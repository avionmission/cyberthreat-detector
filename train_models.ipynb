{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Cybersecurity Threat Detection - Model Training\n",
    "\n",
    "This notebook demonstrates the complete machine learning pipeline for cybersecurity threat detection:\n",
    "1. Load the LogHub dataset\n",
    "2. Extract features from log entries\n",
    "3. Train Random Forest and Isolation Forest models\n",
    "4. Evaluate model performance\n",
    "5. Export models for the web application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loading LogHub dataset...\n",
      "‚úÖ Loaded 5000 log entries\n",
      "   Normal logs: 3000\n",
      "   Threat logs: 2000\n",
      "\n",
      "üìã Dataset columns: ['log', 'label', 'threat_type']\n",
      "\n",
      "üéØ Threat type distribution:\n",
      "threat_type\n",
      "normal                  3000\n",
      "brute_force              400\n",
      "privilege_escalation     400\n",
      "dos_attack               400\n",
      "unauthorized_access      400\n",
      "network_scan             400\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìù Sample log entries:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log</th>\n",
       "      <th>label</th>\n",
       "      <th>threat_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jan 15 14:23:18 server4 apache2[8924]: 192.168...</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jan 21 17:52:15 server3 cron[2786]: (www-data)...</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jan 30 07:50:19 server1 cron[7164]: (service) ...</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jan 16 20:29:27 server2 apache2[7234]: 192.168...</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jan 10 04:03:05 server3 postfix/smtpd[1404]: c...</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 log  label threat_type\n",
       "0  Jan 15 14:23:18 server4 apache2[8924]: 192.168...      0      normal\n",
       "1  Jan 21 17:52:15 server3 cron[2786]: (www-data)...      0      normal\n",
       "2  Jan 30 07:50:19 server1 cron[7164]: (service) ...      0      normal\n",
       "3  Jan 16 20:29:27 server2 apache2[7234]: 192.168...      0      normal\n",
       "4  Jan 10 04:03:05 server3 postfix/smtpd[1404]: c...      0      normal"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the LogHub dataset\n",
    "print(\"üìä Loading LogHub dataset...\")\n",
    "df = pd.read_csv('data/training_dataset.csv')\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(df)} log entries\")\n",
    "print(f\"   Normal logs: {len(df[df['label'] == 0])}\")\n",
    "print(f\"   Threat logs: {len(df[df['label'] == 1])}\")\n",
    "\n",
    "print(\"\\nüìã Dataset columns:\", list(df.columns))\n",
    "print(\"\\nüéØ Threat type distribution:\")\n",
    "print(df['threat_type'].value_counts())\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nüìù Sample log entries:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Extracting features from logs...\n",
      "‚úÖ Extracted 22 features\n",
      "Features: ['log_length', 'word_count', 'char_count', 'failed_count', 'password_count', 'root_count', 'admin_count', 'sudo_count', 'error_count', 'connection_count', 'attack_count', 'ip_count', 'has_external_ip', 'port_count', 'has_suspicious_port', 'hour', 'is_night_time', 'digit_ratio', 'special_char_ratio', 'uppercase_ratio', 'http_status', 'is_http_error']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>failed_count</th>\n",
       "      <th>password_count</th>\n",
       "      <th>root_count</th>\n",
       "      <th>admin_count</th>\n",
       "      <th>sudo_count</th>\n",
       "      <th>error_count</th>\n",
       "      <th>connection_count</th>\n",
       "      <th>...</th>\n",
       "      <th>has_external_ip</th>\n",
       "      <th>port_count</th>\n",
       "      <th>has_suspicious_port</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_night_time</th>\n",
       "      <th>digit_ratio</th>\n",
       "      <th>special_char_ratio</th>\n",
       "      <th>uppercase_ratio</th>\n",
       "      <th>http_status</th>\n",
       "      <th>is_http_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123</td>\n",
       "      <td>15</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>8</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.183099</td>\n",
       "      <td>0.197183</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.185714</td>\n",
       "      <td>0.185714</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123</td>\n",
       "      <td>15</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.398374</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>8</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.144444</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   log_length  word_count  char_count  failed_count  password_count  \\\n",
       "0         123          15         123             0               0   \n",
       "1          71           8          71             0               0   \n",
       "2          70           8          70             0               0   \n",
       "3         123          15         123             0               0   \n",
       "4          90           8          90             0               0   \n",
       "\n",
       "   root_count  admin_count  sudo_count  error_count  connection_count  ...  \\\n",
       "0           0            0           0            0                 0  ...   \n",
       "1           0            0           0            0                 0  ...   \n",
       "2           0            0           0            0                 0  ...   \n",
       "3           0            0           0            0                 0  ...   \n",
       "4           0            0           0            0                 1  ...   \n",
       "\n",
       "   has_external_ip  port_count  has_suspicious_port  hour  is_night_time  \\\n",
       "0                0           0                    0    12              0   \n",
       "1                0           0                    0    12              0   \n",
       "2                0           0                    0    12              0   \n",
       "3                0           0                    0    12              0   \n",
       "4                0           0                    0    12              0   \n",
       "\n",
       "   digit_ratio  special_char_ratio  uppercase_ratio  http_status  \\\n",
       "0     0.414634            0.195122         0.073171            0   \n",
       "1     0.183099            0.197183         0.056338            0   \n",
       "2     0.185714            0.185714         0.057143            0   \n",
       "3     0.398374            0.195122         0.073171            0   \n",
       "4     0.266667            0.144444         0.011111            0   \n",
       "\n",
       "   is_http_error  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_features(log_text):\n",
    "    \"\"\"Extract numerical features from log text\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Basic text features\n",
    "    features['log_length'] = len(log_text)\n",
    "    features['word_count'] = len(log_text.split())\n",
    "    features['char_count'] = len(log_text)\n",
    "    \n",
    "    # Security keywords\n",
    "    features['failed_count'] = len(re.findall(r'failed|fail', log_text, re.IGNORECASE))\n",
    "    features['password_count'] = len(re.findall(r'password', log_text, re.IGNORECASE))\n",
    "    features['root_count'] = len(re.findall(r'\\\\broot\\\\b', log_text, re.IGNORECASE))\n",
    "    features['admin_count'] = len(re.findall(r'admin', log_text, re.IGNORECASE))\n",
    "    features['sudo_count'] = len(re.findall(r'sudo|su:', log_text, re.IGNORECASE))\n",
    "    features['error_count'] = len(re.findall(r'error|denied|invalid|unauthorized', log_text, re.IGNORECASE))\n",
    "    features['connection_count'] = len(re.findall(r'connection|connect', log_text, re.IGNORECASE))\n",
    "    features['attack_count'] = len(re.findall(r'attack|scan|probe|flood', log_text, re.IGNORECASE))\n",
    "    \n",
    "    # IP addresses\n",
    "    ip_pattern = r'\\\\b(?:\\\\d{1,3}\\\\.){3}\\\\d{1,3}\\\\b'\n",
    "    ip_matches = re.findall(ip_pattern, log_text)\n",
    "    features['ip_count'] = len(ip_matches)\n",
    "    features['has_external_ip'] = int(any(not ip.startswith(('192.168.', '10.', '172.')) for ip in ip_matches))\n",
    "    \n",
    "    # Ports\n",
    "    port_pattern = r'port\\\\s+(\\\\d+)'\n",
    "    port_matches = re.findall(port_pattern, log_text, re.IGNORECASE)\n",
    "    features['port_count'] = len(port_matches)\n",
    "    features['has_suspicious_port'] = int(any(int(port) in [22, 23, 21, 3389] for port in port_matches if port.isdigit()))\n",
    "    \n",
    "    # Time features\n",
    "    time_pattern = r'(\\\\d{2}):(\\\\d{2}):(\\\\d{2})'\n",
    "    time_match = re.search(time_pattern, log_text)\n",
    "    if time_match:\n",
    "        hour = int(time_match.group(1))\n",
    "        features['hour'] = hour\n",
    "        features['is_night_time'] = int(hour < 6 or hour > 22)\n",
    "    else:\n",
    "        features['hour'] = 12\n",
    "        features['is_night_time'] = 0\n",
    "    \n",
    "    # Character analysis\n",
    "    features['digit_ratio'] = sum(c.isdigit() for c in log_text) / len(log_text) if log_text else 0\n",
    "    features['special_char_ratio'] = sum(not c.isalnum() and c != ' ' for c in log_text) / len(log_text) if log_text else 0\n",
    "    features['uppercase_ratio'] = sum(c.isupper() for c in log_text) / len(log_text) if log_text else 0\n",
    "    \n",
    "    # HTTP status\n",
    "    http_pattern = r'HTTP/1\\\\.[01]\"\\\\s+(\\\\d{3})'\n",
    "    http_match = re.search(http_pattern, log_text)\n",
    "    if http_match:\n",
    "        status_code = int(http_match.group(1))\n",
    "        features['http_status'] = status_code\n",
    "        features['is_http_error'] = int(status_code >= 400)\n",
    "    else:\n",
    "        features['http_status'] = 0\n",
    "        features['is_http_error'] = 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Extract features from all logs\n",
    "print(\"üîß Extracting features from logs...\")\n",
    "feature_list = [extract_features(log) for log in df['log']]\n",
    "features_df = pd.DataFrame(feature_list)\n",
    "\n",
    "print(f\"‚úÖ Extracted {len(features_df.columns)} features\")\n",
    "print(\"Features:\", list(features_df.columns))\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 4000 samples\n",
      "Test set: 1000 samples\n",
      "‚úÖ Data prepared - Feature matrix shape: (4000, 22)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "X = features_df.values\n",
    "y = df['label'].values\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"‚úÖ Data prepared - Feature matrix shape: {X_train_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üå≤ Training Random Forest...\n",
      "üîç Training Isolation Forest...\n",
      "‚úÖ Models trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest\n",
    "print(\"üå≤ Training Random Forest...\")\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Train Isolation Forest\n",
    "print(\"üîç Training Isolation Forest...\")\n",
    "isolation_forest = IsolationForest(\n",
    "    contamination=0.1,\n",
    "    random_state=42,\n",
    "    n_estimators=100\n",
    ")\n",
    "isolation_forest.fit(X_train_scaled)\n",
    "\n",
    "print(\"‚úÖ Models trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üå≤ Random Forest Results:\n",
      "Accuracy: 0.998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       600\n",
      "           1       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "\n",
      "üîç Isolation Forest Results:\n",
      "Accuracy: 0.691\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.80       600\n",
      "           1       1.00      0.23      0.37       400\n",
      "\n",
      "    accuracy                           0.69      1000\n",
      "   macro avg       0.83      0.61      0.58      1000\n",
      "weighted avg       0.80      0.69      0.63      1000\n",
      "\n",
      "\n",
      "üéØ Top 10 Important Features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>digit_ratio</td>\n",
       "      <td>0.167738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>uppercase_ratio</td>\n",
       "      <td>0.147564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>word_count</td>\n",
       "      <td>0.132499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>special_char_ratio</td>\n",
       "      <td>0.131115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>char_count</td>\n",
       "      <td>0.117146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log_length</td>\n",
       "      <td>0.099466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>failed_count</td>\n",
       "      <td>0.086359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>attack_count</td>\n",
       "      <td>0.027913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sudo_count</td>\n",
       "      <td>0.025745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>connection_count</td>\n",
       "      <td>0.024042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature  importance\n",
       "17         digit_ratio    0.167738\n",
       "19     uppercase_ratio    0.147564\n",
       "1           word_count    0.132499\n",
       "18  special_char_ratio    0.131115\n",
       "2           char_count    0.117146\n",
       "0           log_length    0.099466\n",
       "3         failed_count    0.086359\n",
       "10        attack_count    0.027913\n",
       "7           sudo_count    0.025745\n",
       "9     connection_count    0.024042"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Random Forest\n",
    "rf_pred = rf_model.predict(X_test_scaled)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "print(\"üå≤ Random Forest Results:\")\n",
    "print(f\"Accuracy: {rf_accuracy:.3f}\")\n",
    "print(classification_report(y_test, rf_pred))\n",
    "\n",
    "# Evaluate Isolation Forest\n",
    "if_pred = isolation_forest.predict(X_test_scaled)\n",
    "if_pred_binary = (if_pred == -1).astype(int)\n",
    "if_accuracy = accuracy_score(y_test, if_pred_binary)\n",
    "\n",
    "print(\"\\nüîç Isolation Forest Results:\")\n",
    "print(f\"Accuracy: {if_accuracy:.3f}\")\n",
    "print(classification_report(y_test, if_pred_binary))\n",
    "\n",
    "# Feature importance\n",
    "print(\"\\nüéØ Top 10 Important Features:\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': features_df.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saving models...\n",
      "‚úÖ Models exported successfully!\n",
      "Files saved:\n",
      "  - models/random_forest.pkl\n",
      "  - models/isolation_forest.pkl\n",
      "  - models/scaler.pkl\n",
      "  - models/model_metadata.json\n",
      "\n",
      "üéâ Training Complete!\n",
      "Random Forest Accuracy: 0.998\n",
      "Isolation Forest Accuracy: 0.691\n",
      "Models ready for web application!\n"
     ]
    }
   ],
   "source": [
    "# Create models directory\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save models\n",
    "print(\"üíæ Saving models...\")\n",
    "joblib.dump(rf_model, 'models/random_forest.pkl')\n",
    "joblib.dump(isolation_forest, 'models/isolation_forest.pkl')\n",
    "joblib.dump(scaler, 'models/scaler.pkl')\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'model_version': '1.0',\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'feature_names': list(features_df.columns),\n",
    "    'training_samples': len(X_train),\n",
    "    'test_samples': len(X_test),\n",
    "    'rf_accuracy': float(rf_accuracy),\n",
    "    'if_accuracy': float(if_accuracy),\n",
    "    'feature_count': len(features_df.columns)\n",
    "}\n",
    "\n",
    "with open('models/model_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Models exported successfully!\")\n",
    "print(\"Files saved:\")\n",
    "print(\"  - models/random_forest.pkl\")\n",
    "print(\"  - models/isolation_forest.pkl\")\n",
    "print(\"  - models/scaler.pkl\")\n",
    "print(\"  - models/model_metadata.json\")\n",
    "\n",
    "print(f\"\\nüéâ Training Complete!\")\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.3f}\")\n",
    "print(f\"Isolation Forest Accuracy: {if_accuracy:.3f}\")\n",
    "print(f\"Models ready for web application!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
